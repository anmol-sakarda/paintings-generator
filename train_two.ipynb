{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Reshape, Flatten, Input, BatchNormalization, Dropout, Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caaf05558d2946fe801cb504a51acf77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1216.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def load_data(path, img_dim):\n",
    "    images = []\n",
    "    for file in tqdm(os.listdir(path)):\n",
    "        img = Image.open(os.path.join(path, file)).convert('RGB')\n",
    "        img = img.resize((img_dim, img_dim))\n",
    "        img = np.array(img)\n",
    "        img = (img - 127.5) / 127.5 #why\n",
    "        images.append(img)\n",
    "    return np.asarray(images)\n",
    "\n",
    "\n",
    "data_dir = 'image_folder/Images'\n",
    "img_dim = 128\n",
    "images = load_data(data_dir, img_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    net = Sequential()\n",
    "    net.add(Dense(16 * 16 * 256, input_dim=100))\n",
    "    net.add(BatchNormalization(momentum=0.9))\n",
    "    net.add(Activation('relu'))\n",
    "    net.add(Reshape((16, 16, 256)))\n",
    "    net.add(Dropout(0.4))\n",
    "\n",
    "    net.add(UpSampling2D())\n",
    "    net.add(Conv2D(128, 5, padding='same'))\n",
    "    net.add(BatchNormalization(momentum=0.9))\n",
    "    net.add(Activation('relu'))\n",
    "\n",
    "    net.add(UpSampling2D())\n",
    "    net.add(Conv2D(128, 5, padding='same'))\n",
    "    net.add(BatchNormalization(momentum=0.9))\n",
    "    net.add(Activation('relu'))\n",
    "\n",
    "    net.add(UpSampling2D())\n",
    "    net.add(Conv2D(64, 5, padding='same'))\n",
    "    net.add(BatchNormalization(momentum=0.9))\n",
    "    net.add(Activation('relu'))\n",
    "\n",
    "    net.add(Conv2D(32, 5, padding='same'))\n",
    "    net.add(BatchNormalization(momentum=0.9))\n",
    "    net.add(Activation('relu'))\n",
    "\n",
    "    net.add(Conv2D(3, 5, padding='same'))\n",
    "    net.add(Activation('tanh'))\n",
    "\n",
    "    # net.summary()\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    net = Sequential()\n",
    "    net.add(Conv2D(64, 5, strides=2, input_shape=(128, 128, 3), padding='same'))\n",
    "    net.add(LeakyReLU())\n",
    "\n",
    "    net.add(Conv2D(128, 5, strides=2, padding='same'))\n",
    "    net.add(LeakyReLU())\n",
    "    net.add(Dropout(0.4))\n",
    "\n",
    "    net.add(Conv2D(256, 5, strides=2, padding='same'))\n",
    "    net.add(LeakyReLU())\n",
    "    net.add(Dropout(0.4))\n",
    "\n",
    "    net.add(Conv2D(512, 5, strides=2, padding='same'))\n",
    "    net.add(LeakyReLU())\n",
    "    net.add(Dropout(0.4))\n",
    "\n",
    "    net.add(Flatten())\n",
    "    net.add(Dense(1))\n",
    "    net.add(Activation('sigmoid'))\n",
    "\n",
    "    # net.summary()\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_model = build_discriminator()\n",
    "discriminator_optimizer = RMSprop(lr=0.0002, clipvalue=1.0, decay=6e-8)\n",
    "discriminator_model.compile(loss='binary_crossentropy',\n",
    "                            optimizer=discriminator_optimizer,\n",
    "                            metrics=['accuracy'])\n",
    "\n",
    "adversarial_model = Sequential()\n",
    "generator = build_generator()\n",
    "adversarial_model.add(generator)\n",
    "\n",
    "# discriminator layers frozen so only generator layers will train\n",
    "for layer in discriminator_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "adversarial_model.add(discriminator_model)\n",
    "adversarial_optimizer = Adam(lr=0.0001, clipvalue=1.0, decay=3e-8)\n",
    "adversarial_model.compile(loss='binary_crossentropy',\n",
    "                          optimizer=adversarial_optimizer,\n",
    "                          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, batch_size):\n",
    "    np.random.shuffle(images)\n",
    "    total_steps = images.shape[0] // batch_size\n",
    "\n",
    "    for step in tqdm(range(total_steps)):\n",
    "        # generate fake images by passing random noise into generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        images_fake = generator.predict(noise)\n",
    "\n",
    "        # combine fake and real images\n",
    "        images_real = images[step * batch_size: (step + 1) * batch_size]\n",
    "        x = np.concatenate((images_fake, images_real))\n",
    "\n",
    "        # create training labels\n",
    "        y = np.zeros([2 * batch_size, 1])\n",
    "        y[batch_size:, :] = 1\n",
    "\n",
    "        # train discriminator on fake and real images\n",
    "        d_stats = discriminator_model.train_on_batch(x, y)\n",
    "\n",
    "        # train generator based on ability to fool discriminator\n",
    "        noise = np.random.normal(0, 1, (batch_size * 2, 100))\n",
    "        a_stats = adversarial_model.train_on_batch(noise, np.ones([batch_size * 2, 1]))\n",
    "\n",
    "    print(d_stats)\n",
    "    print(a_stats)\n",
    "    print('---------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1b1138ad11431f89e87ed2aa662dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.0005545263411477208, 1.0]\n",
      "[0.0036892013158649206, 1.0]\n",
      "---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb54ea3ec7a4616b99e9eeb281c7bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.008279316127300262, 0.99609375]\n",
      "[4.75792690836363e-13, 1.0]\n",
      "---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709e68b3b7da4d7cbbbf8281083b3885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.21455253660678864, 0.9140625]\n",
      "[2.2567535876880763e-22, 1.0]\n",
      "---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc473af65549428d847c1de606d26701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.006745525635778904, 0.99609375]\n",
      "[5.5095099235478355e-17, 1.0]\n",
      "---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2212436503224baba3e168b144511ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.023723745718598366, 0.9921875]\n",
      "[32.165382385253906, 0.0]\n",
      "---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3407d6ec2cc340c183eee894f2743d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.8184212446212769, 0.71484375]\n",
      "[7.239023208618164, 0.0]\n",
      "---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06481ca6b9246fb98c91d47e0a4663e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.2119567096233368, 0.91796875]\n",
      "[2.7095611095428467, 0.02734375]\n",
      "---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285469b6c59645b8bc2637abc7d0ce15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.07938089966773987, 0.96484375]\n",
      "[0.03845994174480438, 1.0]\n",
      "---------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d7c48214814fb1ab0275c9db725ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis_noise = np.random.normal(0, 1, (16, 100))\n",
    "\n",
    "\n",
    "def genSample(path, epoch):\n",
    "    generated_images = generator.predict(vis_noise)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    generated_images = (generated_images * 0.5) + 0.5\n",
    "\n",
    "    for im in range(generated_images.shape[0]):\n",
    "        plt.subplot(4, 4, im + 1)\n",
    "        image = generated_images[im, :, :, :]\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plot = path + '/Epoch{}.png'.format(epoch)\n",
    "    plt.savefig(plot)\n",
    "    plt.close('all')\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "training_sample_path = 'ResultEpochs'\n",
    "for epoch in range(1, 51):\n",
    "    genSample(training_sample_path, epoch)\n",
    "    train(epoch, batch_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
